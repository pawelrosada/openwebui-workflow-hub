"""
Gemini Chat Pipeline for Open WebUI
Integracja z Google Gemini Pro przez Langflow
"""

import os
import time
from datetime import datetime
from logging import getLogger
from typing import Generator, Iterator, List, Union

import httpx
from pydantic import BaseModel, Field

logger = getLogger(__name__)
logger.setLevel("DEBUG")

class Pipeline:
    class Valves(BaseModel):
        LANGFLOW_BASE_URL: str = Field(
            default="http://langflow:7860",
            description="URL bazowy do Langflow API"
        )
        WORKFLOW_ID: str = Field(
            default="gemini-chat-basic",
            description="ID przepÅ‚ywu Gemini w Langflow (endpoint_name)"
        )
        RATE_LIMIT: int = Field(
            default=5,
            description="Limit Å¼Ä…daÅ„ na sekundÄ™"
        )
        TIMEOUT: int = Field(
            default=30,
            description="Timeout w sekundach dla Å¼Ä…daÅ„ do Langflow"
        )

    def __init__(self):
        self.name = "Gemini Chat Pipeline"
        self.valves = self.Valves(
            **{k: os.getenv(k, v.default) for k, v in self.Valves.model_fields.items()}
        )

    async def on_startup(self):
        logger.info(f"ğŸš€ Uruchomiono pipeline: {self.name}")
        logger.info(f"ğŸ”— Langflow URL: {self.valves.LANGFLOW_BASE_URL}")
        logger.info(f"ğŸ”„ Workflow ID: {self.valves.WORKFLOW_ID}")
    
    async def on_shutdown(self): 
        logger.info(f"ğŸ›‘ ZamkniÄ™to pipeline: {self.name}")

    def rate_check(self, dt_start: datetime):
        """Sprawdza i wymusza rate limiting"""
        diff = (datetime.now() - dt_start).total_seconds()
        buffer = 1 / self.valves.RATE_LIMIT
        if diff < buffer: 
            time.sleep(buffer - diff)

    def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Union[str, Generator, Iterator]:
        """
        GÅ‚Ã³wna funkcja pipeline - przekazuje wiadomoÅ›Ä‡ do Langflow z Gemini
        """
        logger.debug(f"ğŸ“¨ Przetwarzanie wiadomoÅ›ci przez {self.name}")
        logger.debug(f"ğŸ“‹ WiadomoÅ›Ä‡: {user_message[:100]}...")
        
        dt_start = datetime.now()
        
        try:
            result = "".join([chunk for chunk in self.call_langflow(user_message, dt_start)])
            logger.info(f"âœ… OdpowiedÅº wygenerowana przez Gemini (dÅ‚ugoÅ›Ä‡: {len(result)})")
            return result
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d w pipeline Gemini: {e}")
            return f"ğŸš¨ **BÅ‚Ä…d Gemini Pipeline**: {str(e)}"

    def call_langflow(self, prompt: str, dt_start: datetime) -> Generator:
        """
        WywoÅ‚uje Langflow API z przepÅ‚ywem Gemini
        """
        self.rate_check(dt_start)
        
        # URL do konkretnego przepÅ‚ywu Gemini
        url = f"{self.valves.LANGFLOW_BASE_URL}/api/v1/run/{self.valves.WORKFLOW_ID}?stream=false"
        
        payload = {
            "input_value": prompt,
            "output_type": "chat",
            "input_type": "chat"
        }
        
        headers = {
            "Content-Type": "application/json"
        }
        
        logger.debug(f"ğŸ”— WywoÅ‚ujÄ™ Langflow: {url}")
        logger.debug(f"ğŸ“¦ Payload: {payload}")
        
        try:
            with httpx.Client(timeout=self.valves.TIMEOUT) as client:
                response = client.post(url, json=payload, headers=headers)
                response.raise_for_status()
                
                data = response.json()
                logger.debug(f"ğŸ“¥ OdpowiedÅº Langflow: {data}")
                
                # WyciÄ…gnij tekst odpowiedzi z struktury Langflow
                text = (
                    data.get("outputs", [{}])[0]
                        .get("outputs", [{}])[0]
                        .get("results", {})
                        .get("message", {})
                        .get("text", "Brak odpowiedzi z Gemini")
                )
                
                if text:
                    yield f"ğŸ¤– **Gemini Pro**: {text}"
                else:
                    yield "ğŸš¨ **Gemini Error**: Nie otrzymano odpowiedzi z modelu"
                    
        except httpx.TimeoutException:
            logger.error(f"â° Timeout podczas Å‚Ä…czenia z Langflow")
            yield "ğŸš¨ **Gemini Error**: Przekroczono limit czasu odpowiedzi"
            
        except httpx.HTTPStatusError as e:
            logger.error(f"ğŸš« BÅ‚Ä…d HTTP z Langflow: {e.response.status_code}")
            yield f"ğŸš¨ **Gemini Error**: BÅ‚Ä…d serwera ({e.response.status_code})"
            
        except Exception as e:
            logger.error(f"âŒ Nieoczekiwany bÅ‚Ä…d Langflow: {e}")
            yield f"ğŸš¨ **Gemini Error**: {str(e)}"